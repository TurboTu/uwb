#服务名
spring.application.name=uwb-status
####服务端口###
server.port=11004

mysql.ip=10.21.240.2
mysql.port=3306
mysql.username=mysql_admin
mysql.password=zhilu@2016

kafka.ip=10.21.240.8
kafka.port=9092
kafka.consumer.topic=uwb_original_topic

redis.ip=10.21.0.16
redis.password=Zhilu@2017&SZ#SBN$401!
redis.port=6379

############DomeOs部署###
#zookeeper地址
register.servers=10.21.240.2
env.registry.kafka=${kafka.ip}:${kafka.port}
env.registry.servers=${register.servers}
#模块名
env.registry.module=mia-uwb-status
env.registry.node=1
env.registry.remote=1
env.registry.conf.remote=1
#统一控制接口前缀
server.context-path=/uwb/status
########################################################
###datasource
########################################################
spring.datasource.url=jdbc:mysql://${mysql.ip}:${mysql.port}/uwb?useUnicode=true&characterEncoding=utf-8
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.username=${mysql.username}
spring.datasource.password=${mysql.password}
# 连接池配置,下面配置说明请参考Druid Github Wiki，配置_DruidDataSource参考配置
# 下面为连接池的补充设置，应用到上面所有数据源中
# 初始化大小，最小，最大
spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.minEvictableIdleTimeMillis=300000
#用来检测连接是否有效的sql，要求是一个查询语句，常用select 'x'。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会起作用。
#spring.datasource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.validationQuery=SELECT 'x'
spring.datasource.testWhileIdle=true
#申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
#spring.datasource.poolPreparedStatements=true
#spring.datasource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙（防止SQL注入）
spring.datasource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
#spring.datasource.logSlowSql=true
# 合并多个DruidDataSource的监控数据
#spring.datasource.useGlobalDataSourceStat=true

#######################################################
###tk.mybatis
#######################################################
mapper.mappers=com.zhilutec.uwb.common.MyMapper
mapper.not-empty=false
mapper.identity=MYSQL
#mybatis mapper
#mybatis config
mybatis.config-location=classpath:mybatis/config.xml
#mybatis.executorType=simple
mybatis.type-aliases-package=com.zhilutec.uwb.entity
mybatis.type-handlers-package=com.zhilutec.uwb.dao
#######################################################
###tpageHelper
#######################################################
pagehelper.helperDialect=mysql
pagehelper.reasonable=true
pagehelper.supportMethodsArguments=true
pagehelper.params=count=countSql
#######################################################
###logger
#######################################################
#logging.level.tk.mybatis=TRACE
#mybaits sql show###显示SQL语句部分
#logging.level.com.zhilutec.dbs.daos=warn

#######################################################
#######################Redis###########################
#######################################################
# REDIS (RedisProperties)
# Redis数据库索引（默认为0）
spring.redis.database=6
# Redis服务器地址
spring.redis.host=${redis.ip}
# Redis服务器连接端口
spring.redis.port=${redis.port}
#Redis服务器连接密码（默认为空）
spring.redis.password=${redis.password}
# 连接池最大连接数（使用负值表示没有限制）
spring.redis.pool.max-active=2000
# 连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.pool.max-wait=-1
# 连接池中的最大空闲连接
spring.redis.pool.max-idle=100
# 连接池中的最小空闲连接
spring.redis.pool.min-idle=5
# 连接超时时间（毫秒）
spring.redis.timeout=0

#################kafka######################
#################consumer#########
spring.kafka.consumer.bootstrapServers=${kafka.ip}:${kafka.port}
spring.kafka.consumer.topic=${kafka.consumer.topic}
#自动commmit设置
spring.kafka.consumer.autoOffsetReset=latest
#是否自动commit
spring.kafka.consumer.autoCommit=false
#自动commit间隔
spring.kafka.consumer.autoCommitInterval=1000
#分组
spring.kafka.consumer.groupId=${spring.application.name}-consumer-gid
#客户端Id
spring.kafka.consumer.clientId=${spring.application.name}-consumer-cid
#AckMode为COUNT_TIME或COUNT是限制最多未提交offset的数量
spring.kafka.consumer.ackCount=1000
#AckMode为COUNT_TIME或TIME时设置多久commit一次
spring.kafka.consumer.ackTime=2000
#消费线程的数量
spring.kafka.consumer.concurrency=2
#一次从kafka中poll出来的数据条数
#max.poll.records条数据需要在在session.timeout.ms这个时间内处理完
spring.kafka.consumer.maxPollRecords=50
#poll超时时间
spring.kafka.consumer.maxPollIntervalMs=10000
#服务端poll超时时间设置
spring.kafka.consumer.pollTimeout=300000
#是否批量消费
spring.kafka.consumer.batchListener=true
#Consumer session 过期时间。这个值必须设置在broker configuration中的group.min.session.timeout.ms 与 group.max.session.timeout.ms之间。
#默认为10000ms
spring.kafka.consumer.sessionTimeout=15000
#消息发送的最长等待时间.需大于session.timeout.ms这个时间,默认305000
spring.kafka.consumer.requestInterValMs=305000 
#server发送到消费端的最小数据，若是不满足这个数值则会等待直到满足指定大小。默认为1表示立即接收。
spring.kafka.consumer.fetchMinBytes=1
#若是不满足fetch.min.bytes时，等待消费端请求的最长等待时间
spring.kafka.consumer.fetchWaitMax=1000
#心跳间隔。心跳是在consumer与coordinator之间进行的。这个值必须设置的小于session.timeout.ms，因为：
#当Consumer由于某种原因不能发Heartbeat到coordinator时，并且时间超过session.timeout.ms时，就会认为该consumer已退出
#通常设置的值要低于session.timeout.ms的1/3。默认值是：3000 （3s）
spring.kafka.consumer.heartbeatIntervalMs=5000
uwb.queue.thread.number=4

