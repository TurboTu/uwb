############################################################
###################kafka###################################
############################################################
#是否启动Producer监听器
#自定义参数
spring.kafka.producer.listener=true
#官方配置参数详解
#http://kafka.apache.org/documentation/#configuration
#常用参数说明
#bootstrap.servers=192.168.49.206:9092,192.168.49.205:9092,192.168.49.204:9092 brokers集群
#acks=all     即所有副本都同步到数据时send方法才返回, 以此来完全判断数据是否发送成功, 理论上来讲数据不会丢失.
#retries=10 发送失败重试次数
#batch.size=1638 批处理条数：当多个记录被发送到同一个分区时，生产者会尝试将记录合并到更少的请求中。这有助于客户端和服务器的性能。
#linger.ms=1 批处理延迟时间上限：即1ms过后，不管是否达到批处理数，都直接发送一次请求
#buffer.memory=33554432 即32MB的批处理缓冲区

#这里发布一个真实的公司要求的使用规范，当然比较简单哈，但贵在真实：
#a: Producer 部分参数设定:
#　1: acks 设置为 "all" 即所有副本都同步到数据时send方法才返回, 以此来完全判断数据是否发送成功, 理论上来讲数据不会丢失.
#　2: retries = MAX 无限重试，直到你意识到出现了问题.
#　3: 使用 callback 来处理消息失败发送逻辑.
#　4: min.insync.replicas > 1 消息至少要被写入到这么多副本才算成功，也是提升数据持久性的一个参数。与acks配合使用.
#　5: 其他一些超时参数: reconnect.backoff.ms, retry.backoff.ms , linger.ms 结合 batch.size 等.

#极限情况的数据丢失现象.
#a: 即使将 ack 设置为 "all" 也会在一定情况下丢失消息. 因为 kafka 的高性能特性, 消息在写入 kafka 时并没有落盘 而是写入了 OS buffer 中. 使用 OS 的脏页刷新策略周期性落盘,
# 就算落盘 仍然会有 raid buffer. 前者机器宕机数据丢失, 后者机器跳电数据丢失.
# Number of acknowledgments the producer requires the leader to have received before considering a request complete.
spring.kafka.producer.acks= all
# Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.
spring.kafka.producer.bootstrap-servers= 192.168.10.166:9092
# Total bytes of memory the producer can use to buffer records waiting to be sent to the server.
spring.kafka.producer.buffer-memory= 33554432
# Id to pass to the server when making requests; used for server-side logging.
spring.kafka.producer.client-id=producer-client
# Compression type for all data generated by the producer.
#values are none, gzip, snappy, or lz4.
spring.kafka.producer.compression-type= none
# Number of records to batch before sending.
spring.kafka.producer.batch-size= 16384
spring.kafka.producer.linger-ms = 0
# When greater than zero, enables retrying of failed sends.
spring.kafka.producer.retries= 2
# Serializer class for keys
spring.kafka.producer.key-serializer= org.apache.kafka.common.serialization.StringSerializer
# Serializer class for values.
spring.kafka.producer.value-serializer= org.apache.kafka.common.serialization.StringSerializer
spring.kafka.template.default-topic=positions
# Additional properties used to configure the client.
#spring.kafka.properties.*=